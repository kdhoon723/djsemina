// backend/server.js

import dotenv from "dotenv";
dotenv.config();

import express from "express";
import cors from "cors";
// initializeCrawlerì™€ closeCrawlerë¥¼ import í•©ë‹ˆë‹¤.
import { crawl, initializeCrawler, closeCrawler } from "./crawler.js";

const PORT = process.env.PORT || 8080;
const app = express();
app.use(cors());

// ë©”ëª¨ë¦¬ ìºì‹œ: { date: { ts, data, fetchedAt } }
const cache = new Map();

// --- ìë™ í¬ë¡¤ë§ ì„¤ì • ---
const AUTO_CRAWL_INTERVAL_MS = 10 * 60 * 1000; // 10ë¶„
let autoCrawlIntervalId = null;
let isCrawlerReady = false; // í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ìƒíƒœ í”Œë˜ê·¸

/**
 * í¬ë¡¤ë§ ëŒ€ìƒ ë‚ ì§œë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (í”„ëŸ°íŠ¸ì—”ë“œ ë¡œì§ê³¼ ìœ ì‚¬í•˜ê²Œ)
 * í˜„ì¬ ì‹œê°„ì´ ì˜¤í›„ 8ì‹œ (20ì‹œ) ì´í›„ë©´ ë‹¤ìŒë‚ ì„, ì•„ë‹ˆë©´ ì˜¤ëŠ˜ ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
 */
function getTargetDateForAutoCrawl() {
    const now = new Date();
    // ì„œë²„ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ 20ì‹œ ì²´í¬ (í•„ìš”ì‹œ íŠ¹ì • íƒ€ì„ì¡´ ì ìš© ê³ ë ¤, ì˜ˆ: KST)
    if (now.getHours() >= 20) {
        const tomorrow = new Date(now);
        tomorrow.setDate(now.getDate() + 1);
        return tomorrow.toISOString().slice(0, 10);
    } else {
        return now.toISOString().slice(0, 10);
    }
}


/**
 * ì£¼ê¸°ì ìœ¼ë¡œ ëŒ€ìƒ ë‚ ì§œì˜ ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ê³  ìºì‹œë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜
 */
async function runAutoCrawl() {
    // í¬ë¡¤ëŸ¬ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
    if (!isCrawlerReady) {
        console.log("[Auto Crawl] í¬ë¡¤ëŸ¬ê°€ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ ì£¼ê¸°ì— ì‹œë„í•©ë‹ˆë‹¤.");
        return;
    }
    // *** ìˆ˜ì •ëœ ë¶€ë¶„: í”„ëŸ°íŠ¸ì—”ë“œ ë¡œì§ì— ë§ì¶° í¬ë¡¤ë§ ëŒ€ìƒ ë‚ ì§œ ê²°ì • ***
    const targetDate = getTargetDateForAutoCrawl();
    console.log(`[Auto Crawl] ì£¼ê¸°ì  í¬ë¡¤ë§ ì‹œì‘: ëŒ€ìƒ ë‚ ì§œ=${targetDate}`);
    try {
        const fetchedAt = new Date().toISOString();
        // *** ìˆ˜ì •ëœ ë¶€ë¶„: ê³„ì‚°ëœ targetDateë¡œ í¬ë¡¤ë§ ***
        const rooms = await crawl(targetDate);

        // ìƒˆ ë°ì´í„° ìºì‹œ ì €ì¥
        console.log(`[Auto Crawl] í¬ë¡¤ë§ ì™„ë£Œ. ìºì‹œ ì €ì¥: ${targetDate}, ${rooms.length} rooms`);
        cache.set(targetDate, { ts: Date.now(), data: rooms, fetchedAt });

    } catch (error) {
        console.error(`[Auto Crawl] ì£¼ê¸°ì  í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (${targetDate}):`, error.message);
        // ì—¬ê¸°ì„œ ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ ì£¼ê¸°ì— ë‹¤ì‹œ ì‹œë„
    }
}


// --- API ë¼ìš°íŠ¸ ìˆ˜ì • ---
// '/api/availability' ì—”ë“œí¬ì¸íŠ¸: ìµœì‹  ìºì‹œ ë°˜í™˜ ë˜ëŠ” ê°•ì œ í¬ë¡¤ë§
app.get("/api/availability", async (req, res) => {
    // *** API ìš”ì²­ ì‹œ ë‚ ì§œ ê²°ì • ë¡œì§ì€ ê¸°ì¡´ ìœ ì§€ (í”„ë¡ íŠ¸ì—ì„œ ëª…ì‹œì  ìš”ì²­) ***
    // ê¸°ë³¸ê°’ì„ ìë™ í¬ë¡¤ë§ ëŒ€ìƒ ë‚ ì§œë¡œ ì„¤ì •í•˜ë©´, í”„ë¡ íŠ¸ ì²« ë¡œë”© ì‹œ ë°±ì—”ë“œ ìë™ í¬ë¡¤ë§ê³¼ ê°™ì€ ë‚ ì§œë¥¼ ë³´ê²Œ ë¨
    const date = req.query.date || getTargetDateForAutoCrawl();
    const forceCrawl = req.query._ts !== undefined; // _ts íŒŒë¼ë¯¸í„°ê°€ ìˆìœ¼ë©´ ê°•ì œ í¬ë¡¤ë§ (ë¡± í”„ë ˆìŠ¤ìš©)
    const entry = cache.get(date); // ìš”ì²­ëœ ë‚ ì§œì˜ ìºì‹œ í™•ì¸

    console.log(`[API /availability] ìš”ì²­ ìˆ˜ì‹ : date=${date}, forceCrawl=${forceCrawl}`);

    // 1. ê°•ì œ í¬ë¡¤ë§ ìš”ì²­ (_ts íŒŒë¼ë¯¸í„° ì¡´ì¬)
    if (forceCrawl) {
        console.log(`[API /availability] ê°•ì œ í¬ë¡¤ë§ ìš”ì²­: ${date}.`);
        // í¬ë¡¤ë§ ìˆ˜í–‰
        try {
            const fetchedAt = new Date().toISOString();
            const rooms = await crawl(date); // ìš”ì²­ëœ ë‚ ì§œë¡œ í¬ë¡¤ë§

            // ìƒˆ ë°ì´í„° ìºì‹œ ì €ì¥ (í¬ë¡¤ë§ ê²°ê³¼ë¡œ ìºì‹œ ì—…ë°ì´íŠ¸)
            console.log(`[API /availability] ê°•ì œ í¬ë¡¤ë§ ì™„ë£Œ. ìºì‹œ ì—…ë°ì´íŠ¸: ${date}, ${rooms.length} rooms`);
            cache.set(date, { ts: Date.now(), data: rooms, fetchedAt });

            return res.json({
                date,
                cached: false, // ìƒˆë¡œ í¬ë¡¤ë§í–ˆìœ¼ë¯€ë¡œ false
                fetchedAt: fetchedAt,
                rooms: rooms,
            });
        } catch (error) {
            console.error(`[/api/availability] ê°•ì œ í¬ë¡¤ë§ ì˜¤ë¥˜ (date: ${date}):`, error);
            return res.status(500).json({ error: "Failed to fetch availability data.", message: error.message });
        }
    }

    // 2. ì¼ë°˜ ìš”ì²­ (ê°•ì œ í¬ë¡¤ë§ ì•„ë‹˜) - ìºì‹œëœ ë°ì´í„° ë°˜í™˜ ì‹œë„
    if (entry) {
        console.log(`[API /availability] ìºì‹œ íˆíŠ¸: date=${date}`);
        return res.json({
            date,
            cached: true, // ìºì‹œì—ì„œ ê°€ì ¸ì™”ìœ¼ë¯€ë¡œ true
            fetchedAt: entry.fetchedAt,
            rooms: entry.data,
        });
    }

    // 3. ì¼ë°˜ ìš”ì²­ì¸ë° ìºì‹œê°€ ì—†ëŠ” ê²½ìš° (ì˜ˆ: ì„œë²„ ì‹œì‘ ì§í›„ ë‹¤ë¥¸ ë‚ ì§œ ì¡°íšŒ) - í¬ë¡¤ë§ ìˆ˜í–‰
    console.log(`[API /availability] ìºì‹œ ë¯¸ìŠ¤ (ì¼ë°˜ ìš”ì²­): ${date}. í¬ë¡¤ë§ ì‹œì‘.`);
    try {
        const fetchedAt = new Date().toISOString();
        const rooms = await crawl(date); // ìš”ì²­ëœ ë‚ ì§œë¡œ í¬ë¡¤ë§

        // ìƒˆ ë°ì´í„° ìºì‹œ ì €ì¥
        console.log(`[API /availability] ìºì‹œ ë¯¸ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ. ìºì‹œ ì €ì¥: ${date}, ${rooms.length} rooms`);
        cache.set(date, { ts: Date.now(), data: rooms, fetchedAt });

        return res.json({
            date,
            cached: false, // ìƒˆë¡œ í¬ë¡¤ë§í–ˆìœ¼ë¯€ë¡œ false
            fetchedAt: fetchedAt,
            rooms: rooms,
        });
    } catch (error) {
        console.error(`[/api/availability] ìºì‹œ ë¯¸ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜ (date: ${date}):`, error);
        return res.status(500).json({ error: "Failed to fetch availability data.", message: error.message });
    }
});


// '/api/crawl' ì—”ë“œí¬ì¸íŠ¸ëŠ” ìœ ì§€ (ë””ë²„ê¹… ë˜ëŠ” íŠ¹ì • ëª©ì ìš©)
app.get("/api/crawl", async (req, res) => {
    // '/api/crawl' ì§ì ‘ í˜¸ì¶œ ì‹œ ë‚ ì§œëŠ” ìš”ì²­ íŒŒë¼ë¯¸í„° ë˜ëŠ” ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
    const date = req.query.date || new Date().toISOString().slice(0, 10);
    console.log(`[API /crawl] ì§ì ‘ í¬ë¡¤ë§ ìš”ì²­ ìˆ˜ì‹ : date=${date}`);
    try {
        const fetchedAt = new Date().toISOString();
        const rooms = await crawl(date); // crawl í•¨ìˆ˜ í˜¸ì¶œ

        // ìƒˆ ë°ì´í„° ìºì‹œ ì €ì¥ (ì§ì ‘ í¬ë¡¤ë§ ê²°ê³¼ë„ ìºì‹œ ì—…ë°ì´íŠ¸)
        console.log(`[API /crawl] ì§ì ‘ í¬ë¡¤ë§ ì™„ë£Œ. ìºì‹œ ì—…ë°ì´íŠ¸: ${date}, ${rooms.length} rooms`);
        cache.set(date, { ts: Date.now(), data: rooms, fetchedAt });

        res.json({
            date,
            cached: false, // í•­ìƒ ìƒˆë¡œ ê°€ì ¸ì™”ìœ¼ë¯€ë¡œ false
            fetchedAt: fetchedAt,
            rooms: rooms,
        });
    } catch (error) {
        console.error(`[/api/crawl] Error:`, error);
        res.status(500).json({ error: "Failed to fetch availability data.", message: error.message });
    }
});


// --- ì„œë²„ ì‹œì‘ ë° ì¢…ë£Œ ì²˜ë¦¬ ---

// ì„œë²„ ì‹œì‘ ì „ì— í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ë° ìë™ í¬ë¡¤ë§ ì‹œì‘
(async () => {
    try {
        await initializeCrawler(); // í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” í•¨ìˆ˜ í˜¸ì¶œ
        console.log("âœ… í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì„±ê³µ.");
        isCrawlerReady = true; // í¬ë¡¤ëŸ¬ ì¤€ë¹„ ì™„ë£Œ ìƒíƒœë¡œ ì„¤ì •

        // ì´ˆê¸°í™” ì„±ê³µ ì‹œ ì¦‰ì‹œ ì˜¤ëŠ˜ ë°ì´í„° í¬ë¡¤ë§ í•œë²ˆ ì‹¤í–‰ (ì„œë²„ ì‹œì‘ ì‹œ ìµœì‹  ë°ì´í„° í™•ë³´)
        console.log("[ì´ˆê¸° ì‹¤í–‰] ì„œë²„ ì‹œì‘ í›„ ì²« ìë™ í¬ë¡¤ë§ ì‹¤í–‰ (ëŒ€ìƒ ë‚ ì§œ ê³„ì‚°)...");
        // *** ìˆ˜ì •ëœ ë¶€ë¶„: ìˆ˜ì •ëœ runAutoCrawl í˜¸ì¶œ ***
        await runAutoCrawl(); // ì²« í¬ë¡¤ë§ ì‹¤í–‰ (ìˆ˜ì •ëœ ë¡œì§ìœ¼ë¡œ ëŒ€ìƒ ë‚ ì§œ ê³„ì‚°)

        // ì£¼ê¸°ì  í¬ë¡¤ë§ ì‹œì‘ (ì²« ì‹¤í–‰ í›„ ì„¤ì •)
        // *** ìˆ˜ì •ëœ ë¶€ë¶„: AUTO_CRAWL_INTERVAL_MS ë³€ìˆ˜ ì‚¬ìš© í™•ì¸ ***
        console.log(`[Auto Crawl] ${AUTO_CRAWL_INTERVAL_MS / 60000}ë¶„ ê°„ê²©ìœ¼ë¡œ ìë™ í¬ë¡¤ë§ ì„¤ì •.`);
        autoCrawlIntervalId = setInterval(runAutoCrawl, AUTO_CRAWL_INTERVAL_MS);

        // ì´ˆê¸°í™” ë° ì²« í¬ë¡¤ë§ ì„±ê³µ í›„ ì„œë²„ ë¦¬ìŠ¤ë‹ ì‹œì‘
        app.listen(PORT, () => {
            console.log(`ğŸš€ Server listening on http://0.0.0.0:${PORT}`);
        });
    } catch (error) {
        console.error("âŒ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ë˜ëŠ” ì²« í¬ë¡¤ë§ ì‹¤íŒ¨. ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", error);
        // í¬ë¡¤ëŸ¬ê°€ ì¤€ë¹„ ì•ˆëœ ìƒíƒœë¡œ ë‚¨ì•„ìˆê±°ë‚˜, ì—ëŸ¬ ë°œìƒ ì‹œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
        process.exit(1);
    }
})();


// ì •ìƒ ì¢…ë£Œ ì²˜ë¦¬ (Ctrl+C ë“±) - Interval í´ë¦¬ì–´ ì¶”ê°€
process.on('SIGINT', async () => {
    console.log('\nSIGINT signal received. Closing crawler and exiting...');
    if (autoCrawlIntervalId) {
        clearInterval(autoCrawlIntervalId); // ì£¼ê¸°ì  í¬ë¡¤ë§ ì¤‘ì§€
        console.log("[ì¢…ë£Œ] ìë™ í¬ë¡¤ë§ Interval ì¤‘ì§€ë¨.");
    }
    await closeCrawler(); // í¬ë¡¤ëŸ¬ ì¢…ë£Œ í•¨ìˆ˜ í˜¸ì¶œ
    process.exit(0);
});

// ë‹¤ë¥¸ ì¢…ë£Œ ì‹ í˜¸ ì²˜ë¦¬ (ì„ íƒì ) - Interval í´ë¦¬ì–´ ì¶”ê°€
process.on('SIGTERM', async () => {
    console.log('SIGTERM signal received. Closing crawler and exiting...');
     if (autoCrawlIntervalId) {
        clearInterval(autoCrawlIntervalId); // ì£¼ê¸°ì  í¬ë¡¤ë§ ì¤‘ì§€
        console.log("[ì¢…ë£Œ] ìë™ í¬ë¡¤ë§ Interval ì¤‘ì§€ë¨.");
    }
    await closeCrawler(); // í¬ë¡¤ëŸ¬ ì¢…ë£Œ í•¨ìˆ˜ í˜¸ì¶œ
    process.exit(0);
});

// ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸ ì²˜ë¦¬ (ê¸°ì¡´ ìœ ì§€)
process.on('uncaughtException', (error, origin) => {
    console.error(`\n\n========= UNCAUGHT EXCEPTION =========`);
    console.error(`Origin: ${origin}`);
    console.error(error);
    console.error(`======================================`);
    // ìë™ í¬ë¡¤ë§ Interval ì •ë¦¬ ì‹œë„ (ì„ íƒì )
    if (autoCrawlIntervalId) clearInterval(autoCrawlIntervalId);
    // í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ìê°€ ì¬ì‹œì‘í•˜ë„ë¡ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
    process.exit(1); // ë¡œê¹… í›„ ì¢…ë£Œ
});

// ì²˜ë¦¬ë˜ì§€ ì•Šì€ í”„ë¡œë¯¸ìŠ¤ ê±°ë¶€ ì²˜ë¦¬ (ê¸°ì¡´ ìœ ì§€)
process.on('unhandledRejection', (reason, promise) => {
    console.error(`\n\n======= UNHANDLED REJECTION ========`);
    console.error('Promise:', promise);
    console.error('Reason:', reason);
    console.error(`======================================`);
    // ì—¬ê¸°ì„œ í¬ë¡¤ëŸ¬ë¥¼ ë‹«ê±°ë‚˜ Intervalì„ ì •ë¦¬í•˜ëŠ” ê²ƒì€ ìœ„í—˜í•  ìˆ˜ ìˆìŒ
});
